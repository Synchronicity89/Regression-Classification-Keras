{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Classes For Deep Learning models using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a classes to predict the results.\n",
    "\n",
    "Here we alter the datasets in a slightly random way to prove that the class is generalized and flexible.  Problems and bugs will be left in the code so engineers studying machine learning have to be active hands-on instead of merely cloning and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Class using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will randomly alter the hourly wages data using pandas.  To learn that on your own try this: https://github.com/Synchronicity89/Minimally-Sufficient-Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     wage_per_hour  union  education_yrs  experience_yrs  age  female  marr  \\\n",
      "0         5.123964      0              8              21   35       1     1   \n",
      "1         5.934894      0              9              42   57       1     1   \n",
      "2         2.484907      0             12               1   19       0     0   \n",
      "3         3.871201      0             12               4   22       0     0   \n",
      "4         5.318120      0             12              17   35       0     1   \n",
      "5         4.762174      1             13               9   28       0     0   \n",
      "6         5.598422      0             10              27   43       0     0   \n",
      "7         4.682131      0             12               9   27       0     0   \n",
      "8         5.170484      0             16              11   33       0     1   \n",
      "9         4.682131      0             12               9   27       0     0   \n",
      "10        5.318120      1             12              17   35       0     1   \n",
      "11        5.429346      1             12              19   37       0     0   \n",
      "12        5.375278      0              8              27   41       0     1   \n",
      "13        5.598422      1              9              30   45       0     0   \n",
      "14        5.564520      0              9              29   44       0     1   \n",
      "15        6.095825      0             12              37   55       0     1   \n",
      "16        5.730100      0              7              44   57       0     1   \n",
      "17        5.743003      1             12              26   44       0     1   \n",
      "18        5.170484      0             11              16   33       0     0   \n",
      "19        5.981414      0             12              33   51       0     1   \n",
      "20        5.257495      1             12              16   34       1     1   \n",
      "21        5.683580      1              7              42   55       0     1   \n",
      "22        4.682131      0             12               9   27       0     0   \n",
      "23        5.036953      0             11              14   31       0     1   \n",
      "24        5.620401      0             12              23   41       0     1   \n",
      "25        5.598422      0              6              45   57       0     1   \n",
      "26        4.564348      0             12               8   26       0     1   \n",
      "27        5.703782      0             10              30   46       0     1   \n",
      "28        4.564348      0             12               8   26       1     1   \n",
      "29        4.564348      0             12               8   26       0     1   \n",
      "..             ...    ...            ...             ...  ...     ...   ...   \n",
      "504       5.135798      0             17              10   33       1     0   \n",
      "505       5.075174      1             16              10   32       1     0   \n",
      "506       5.605802      0             16              17   39       1     1   \n",
      "507       4.836282      0             18               7   31       0     1   \n",
      "508       5.411646      0             16              14   36       1     1   \n",
      "509       5.863631      1             16              22   44       1     1   \n",
      "510       5.472271      0             17              14   37       1     1   \n",
      "511       5.170484      0             16              11   33       0     1   \n",
      "512       6.025866      1             18              23   47       0     1   \n",
      "513       6.148468      1             12              39   57       0     1   \n",
      "514       5.480639      0             16              15   37       0     1   \n",
      "515       5.347108      0             14              15   35       1     0   \n",
      "516       5.075174      0             16              10   32       0     0   \n",
      "517       5.703782      0             12              25   43       1     0   \n",
      "518       5.123964      0             14              12   32       1     1   \n",
      "519       4.718499      0             16               7   29       1     1   \n",
      "520       4.779123      1             17               7   30       0     1   \n",
      "521       5.605802      0             16              17   39       0     1   \n",
      "522       5.075174      1             16              10   32       0     1   \n",
      "523       3.526361      0             17               2   25       0     1   \n",
      "524       5.723585      1              9              34   49       1     1   \n",
      "525       5.105945      0             15              11   32       1     1   \n",
      "526       5.010635      0             15              10   31       0     0   \n",
      "527       4.969813      0             12              12   30       0     1   \n",
      "528       4.564348      1             16               6   28       1     0   \n",
      "529       4.499810      0             18               5   29       0     0   \n",
      "530       5.981414      0             12              33   51       1     1   \n",
      "531       6.052089      1             17              25   48       1     1   \n",
      "532       5.049856      1             12              13   31       0     1   \n",
      "533       6.269096      0             16              33   55       0     1   \n",
      "\n",
      "     south  manufacturing  construction  \n",
      "0        0              1             0  \n",
      "1        0              1             0  \n",
      "2        0              1             0  \n",
      "3        0              0             0  \n",
      "4        0              0             0  \n",
      "5        0              0             0  \n",
      "6        1              0             0  \n",
      "7        0              0             0  \n",
      "8        0              1             0  \n",
      "9        0              0             0  \n",
      "10       0              0             0  \n",
      "11       0              1             0  \n",
      "12       1              0             0  \n",
      "13       1              0             0  \n",
      "14       1              0             0  \n",
      "15       0              0             1  \n",
      "16       1              0             0  \n",
      "17       0              1             0  \n",
      "18       0              0             0  \n",
      "19       0              0             0  \n",
      "20       0              1             0  \n",
      "21       0              1             0  \n",
      "22       0              0             0  \n",
      "23       1              0             0  \n",
      "24       0              0             0  \n",
      "25       1              1             0  \n",
      "26       0              1             0  \n",
      "27       0              0             0  \n",
      "28       0              1             0  \n",
      "29       0              0             0  \n",
      "..     ...            ...           ...  \n",
      "504      0              0             0  \n",
      "505      0              0             0  \n",
      "506      0              0             0  \n",
      "507      0              0             0  \n",
      "508      0              0             0  \n",
      "509      0              0             0  \n",
      "510      0              0             0  \n",
      "511      0              0             0  \n",
      "512      0              0             0  \n",
      "513      0              0             0  \n",
      "514      0              0             0  \n",
      "515      0              0             0  \n",
      "516      0              0             0  \n",
      "517      1              0             0  \n",
      "518      0              0             0  \n",
      "519      1              0             0  \n",
      "520      0              0             0  \n",
      "521      0              1             0  \n",
      "522      0              0             0  \n",
      "523      1              0             0  \n",
      "524      1              0             0  \n",
      "525      0              0             0  \n",
      "526      0              0             0  \n",
      "527      1              0             0  \n",
      "528      0              0             0  \n",
      "529      0              0             0  \n",
      "530      0              0             0  \n",
      "531      0              0             0  \n",
      "532      1              0             0  \n",
      "533      0              1             0  \n",
      "\n",
      "[534 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baker\\AppData\\Local\\conda\\conda\\envs\\p35\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#read in training data\n",
    "#train_df = pd.read_html(\"https://github.com/eijaz1/Deep-Learning-in-Keras-Tutorial/blob/master/data/hourly_wages_data.csv\")\n",
    "train_df = pd.read_csv('Datasets/hourly_wages_data.csv')\n",
    "\n",
    "#alter data structure\n",
    "#With any library that is too foreign or confusing, create your own wrapper that is similar to a language/framework you are familiar with\n",
    "#Mine is .NET, yours could be different.  In .NET there are DataSet, DataRow etc\n",
    "#Then eventually everything you actually use is in that wrapper. Of course copy it to its own py file and make a library and reuse it.\n",
    "#So there is no need to copy/paste code every time.  Here I will try to use Pandas without making a wrapper\n",
    "filt = (train_df['education_yrs'] > 0) & (train_df['experience_yrs'] > 0)\n",
    "\n",
    "train_df.loc[filt, 'wage_per_hour'] = np.log(train_df['education_yrs'] * train_df['experience_yrs'])\n",
    "\n",
    "print(train_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to split up our dataset into inputs (train_X) and our target (train_y). Our input will be every column except 'wage_per_hour' because 'wage_per_hour' is what we will be attempting to predict. Therefore, 'wage_per_hour' will be our target.\n",
    "\n",
    "We will use the pandas 'drop' function to drop the column 'wage_per_hour' from our dataframe and store it in the variable 'train_X'. This will be our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>union</th>\n",
       "      <th>education_yrs</th>\n",
       "      <th>experience_yrs</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>marr</th>\n",
       "      <th>south</th>\n",
       "      <th>manufacturing</th>\n",
       "      <th>construction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   union  education_yrs  experience_yrs  age  female  marr  south  \\\n",
       "0      0              8              21   35       1     1      0   \n",
       "1      0              9              42   57       1     1      0   \n",
       "2      0             12               1   19       0     0      0   \n",
       "3      0             12               4   22       0     0      0   \n",
       "4      0             12              17   35       0     1      0   \n",
       "\n",
       "   manufacturing  construction  \n",
       "0              1             0  \n",
       "1              1             0  \n",
       "2              1             0  \n",
       "3              0             0  \n",
       "4              0             0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with all training data except the target column\n",
    "train_X = train_df.drop(columns=['wage_per_hour'])\n",
    "\n",
    "#check that the target variable has been removed\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wage_per_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.123964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.934894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.484907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.871201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.318120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wage_per_hour\n",
       "0       5.123964\n",
       "1       5.934894\n",
       "2       2.484907\n",
       "3       3.871201\n",
       "4       5.318120"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with only the target column\n",
    "train_y = train_df[['wage_per_hour']]\n",
    "\n",
    "#view dataframe\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model type that we will be using is Sequential. Sequential is the easiest way to build a model in Keras. It allows you to build a model layer by layer. Each layer has weights that correspond to the layer the follows it.\n",
    "\n",
    "We use the 'add()' function to add layers to our model. We will add two layers and an output layer.\n",
    "\n",
    "'Dense' is the layer type. Dense is a standard layer type that works for most cases. In a dense layer, all nodes in the previous layer connect to the nodes in the current layer.\n",
    "\n",
    "We have 10 nodes in each of our input layers. This number can also be in the hundreds or thousands. Increasing the number of nodes in each layer increases model capacity. I will go into further detail about the effects of increasing model capacity shortly.\n",
    "\n",
    "'Activation' is the activation function for the layer. An activation function allows models to take into account nonlinear relationships. For example, if you are predicting diabetes in patients, going from age 10 to 11 is different than going from age 60Ã¢??61.\n",
    "\n",
    "The activation function we will be using is ReLU or Rectified Linear Activation. Although it is two linear pieces, it has been proven to work well in neural networks.\n",
    "\n",
    "The first layer needs an input shape. The input shape specifies the number of rows and columns in the input. The number of columns in our input is stored in 'n_cols'. There is nothing after the comma which indicates that there can be any amount of rows.\n",
    "\n",
    "The last layer is the output layer. It only has one node, which is for our prediction.\n",
    "\n",
    "Next, we need to compile our model. Compiling the model takes two parameters: optimizer and loss.\n",
    "\n",
    "The optimizer controls the learning rate. We will be using 'Adam' as our optimizer. Adam is generally a good optimizer to use for many cases. The Adam optimizer adjusts the learning rate throughout training.\n",
    "\n",
    "The learning rate determines how fast the optimal weights for the model are calculated. A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
    "\n",
    "For our loss function, we will use 'mean_squared_error'. It is calculated by taking the average squared difference between the predicted and actual values. It is a popular loss function for regression problems. The closer to 0 this is, the better the model performed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = K.tensorflow_backend._get_available_gpus()\n",
    "processor = ('/gpu:' + str(len(gpus)-1)) if len(gpus) > 0 else '/cpu:0'\n",
    "\n",
    "with tf.device(processor):\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "\n",
    "    #get number of columns in training data\n",
    "    n_cols = train_X.shape[1]\n",
    "\n",
    "    #add model layers\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    #compile model using mse as a measure of model performance\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    #set early stopping monitor so the model stops training when it won't improve anymore\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train our model. To train, we will use the 'fit()' function on our model with the following five parameters: training data (train_X), target data (train_y), validation split, the number of epochs and callbacks.\n",
    "\n",
    "The validation split will randomly split the data into use for training and testing. During training, we will be able to see the validation loss, which gives the mean squared error of our model on the validation set. We will set the validation split at 0.2, which means that 20% of the training data we provide in the model will be set aside for testing model performance.\n",
    "\n",
    "The number of epochs is the number of times the model will cycle through the data. The more epochs we run, the more the model will improve, up to a certain point. After that point, the model will stop improving during each epoch. In addition, the more epochs, the longer the model will take to run. To monitor this, we will use 'early stopping'.\n",
    "\n",
    "Early stopping will stop the model from training before the number of epochs is reached if the model stops improving. We will set our early stopping monitor to 3. This means that after 3 epochs in a row in which the model doesn't improve, training will stop. Sometimes, the validation loss can stop improving then improve in the next epoch, but after 3 epochs in which the validation loss doesn't improve, it usually won't improve again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 427 samples, validate on 107 samples\n",
      "Epoch 1/30\n",
      "427/427 [==============================] - 0s 1ms/step - loss: 454.5973 - val_loss: 318.9381\n",
      "Epoch 2/30\n",
      "427/427 [==============================] - 0s 173us/step - loss: 337.4681 - val_loss: 239.0106\n",
      "Epoch 3/30\n",
      "427/427 [==============================] - 0s 166us/step - loss: 251.5616 - val_loss: 183.9263\n",
      "Epoch 4/30\n",
      "427/427 [==============================] - 0s 154us/step - loss: 189.5674 - val_loss: 145.4595\n",
      "Epoch 5/30\n",
      "427/427 [==============================] - 0s 154us/step - loss: 146.2999 - val_loss: 117.1560\n",
      "Epoch 6/30\n",
      "427/427 [==============================] - 0s 157us/step - loss: 113.8245 - val_loss: 95.1978\n",
      "Epoch 7/30\n",
      "427/427 [==============================] - 0s 152us/step - loss: 88.2571 - val_loss: 77.9270\n",
      "Epoch 8/30\n",
      "427/427 [==============================] - 0s 159us/step - loss: 68.5609 - val_loss: 63.6309\n",
      "Epoch 9/30\n",
      "427/427 [==============================] - 0s 164us/step - loss: 52.4182 - val_loss: 51.9927\n",
      "Epoch 10/30\n",
      "427/427 [==============================] - 0s 168us/step - loss: 39.6562 - val_loss: 42.3475\n",
      "Epoch 11/30\n",
      "427/427 [==============================] - 0s 154us/step - loss: 29.7722 - val_loss: 34.1427\n",
      "Epoch 12/30\n",
      "427/427 [==============================] - 0s 161us/step - loss: 22.4224 - val_loss: 28.3636\n",
      "Epoch 13/30\n",
      "427/427 [==============================] - 0s 152us/step - loss: 18.0117 - val_loss: 24.5203\n",
      "Epoch 14/30\n",
      "427/427 [==============================] - 0s 159us/step - loss: 15.1287 - val_loss: 21.7020\n",
      "Epoch 15/30\n",
      "427/427 [==============================] - 0s 164us/step - loss: 13.1476 - val_loss: 19.5398\n",
      "Epoch 16/30\n",
      "427/427 [==============================] - 0s 175us/step - loss: 11.7642 - val_loss: 17.8333\n",
      "Epoch 17/30\n",
      "427/427 [==============================] - 0s 173us/step - loss: 10.7920 - val_loss: 16.4546\n",
      "Epoch 18/30\n",
      "427/427 [==============================] - 0s 171us/step - loss: 10.0997 - val_loss: 15.3587\n",
      "Epoch 19/30\n",
      "427/427 [==============================] - 0s 175us/step - loss: 9.5919 - val_loss: 14.5083\n",
      "Epoch 20/30\n",
      "427/427 [==============================] - 0s 168us/step - loss: 9.2095 - val_loss: 13.7340\n",
      "Epoch 21/30\n",
      "427/427 [==============================] - 0s 166us/step - loss: 8.9101 - val_loss: 13.0478\n",
      "Epoch 22/30\n",
      "427/427 [==============================] - 0s 173us/step - loss: 8.6056 - val_loss: 12.5745\n",
      "Epoch 23/30\n",
      "427/427 [==============================] - 0s 154us/step - loss: 8.3496 - val_loss: 12.1407\n",
      "Epoch 24/30\n",
      "427/427 [==============================] - 0s 173us/step - loss: 8.0957 - val_loss: 11.7212\n",
      "Epoch 25/30\n",
      "427/427 [==============================] - 0s 168us/step - loss: 7.8424 - val_loss: 11.3023\n",
      "Epoch 26/30\n",
      "427/427 [==============================] - 0s 157us/step - loss: 7.5934 - val_loss: 10.9502\n",
      "Epoch 27/30\n",
      "427/427 [==============================] - 0s 159us/step - loss: 7.3569 - val_loss: 10.6393\n",
      "Epoch 28/30\n",
      "427/427 [==============================] - 0s 154us/step - loss: 7.1260 - val_loss: 10.2614\n",
      "Epoch 29/30\n",
      "427/427 [==============================] - 0s 157us/step - loss: 6.9015 - val_loss: 9.9549\n",
      "Epoch 30/30\n",
      "427/427 [==============================] - 0s 152us/step - loss: 6.6827 - val_loss: 9.6646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b50d4e48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit(train_X, train_y, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on new data\n",
    "\n",
    "If you want to use this model to make predictions on new data, we would use the 'predict()' function, passing in our new data.\n",
    "The output would be 'wage_per_hour' predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.58708096e+00]\n",
      " [ 8.76239586e+00]\n",
      " [ 3.64182770e-01]\n",
      " [ 6.68535113e-01]\n",
      " [ 3.41246963e+00]\n",
      " [ 1.42931485e+00]\n",
      " [ 5.57780504e+00]\n",
      " [ 1.65348697e+00]\n",
      " [ 1.59766364e+00]\n",
      " [ 1.65348697e+00]\n",
      " [ 3.32847977e+00]\n",
      " [ 3.81866622e+00]\n",
      " [ 5.78581667e+00]\n",
      " [ 6.17308760e+00]\n",
      " [ 6.12238741e+00]\n",
      " [ 7.47785187e+00]\n",
      " [ 9.28798962e+00]\n",
      " [ 5.32926941e+00]\n",
      " [ 3.23157072e+00]\n",
      " [ 6.70726109e+00]\n",
      " [ 3.09120631e+00]\n",
      " [ 8.89943790e+00]\n",
      " [ 1.65348697e+00]\n",
      " [ 2.88518047e+00]\n",
      " [ 4.66584444e+00]\n",
      " [ 9.67216587e+00]\n",
      " [ 1.42270529e+00]\n",
      " [ 6.23616171e+00]\n",
      " [ 1.30457783e+00]\n",
      " [ 1.43028009e+00]\n",
      " [ 2.34767652e+00]\n",
      " [ 9.20116329e+00]\n",
      " [ 4.14874506e+00]\n",
      " [-8.71518254e-02]\n",
      " [ 3.90265632e+00]\n",
      " [ 7.24038506e+00]\n",
      " [ 4.03427982e+00]\n",
      " [ 6.99542999e+00]\n",
      " [ 5.57322979e-01]\n",
      " [ 1.53541613e+00]\n",
      " [-6.01648092e-02]\n",
      " [ 2.42274308e+00]\n",
      " [ 2.86097431e+00]\n",
      " [ 3.50937629e+00]\n",
      " [ 1.08189607e+00]\n",
      " [ 3.46311116e+00]\n",
      " [ 1.83319569e+00]\n",
      " [ 2.70428228e+00]\n",
      " [ 6.89894962e+00]\n",
      " [ 1.64813614e+00]\n",
      " [ 1.20484900e+00]\n",
      " [ 1.97865951e+00]\n",
      " [ 1.12087333e+00]\n",
      " [ 3.24922824e+00]\n",
      " [-8.21481645e-02]\n",
      " [ 2.04601192e+00]\n",
      " [ 3.39912891e+00]\n",
      " [ 2.87849116e+00]\n",
      " [ 4.44535398e+00]\n",
      " [ 5.73132277e+00]\n",
      " [ 3.44046664e+00]\n",
      " [ 4.77220964e+00]\n",
      " [ 1.18950815e+01]\n",
      " [ 5.60349941e-01]\n",
      " [ 9.81154203e-01]\n",
      " [ 5.59247637e+00]\n",
      " [ 3.89006782e+00]\n",
      " [ 3.72773004e+00]\n",
      " [ 7.75171423e+00]\n",
      " [ 8.51563072e+00]\n",
      " [ 6.51063442e-01]\n",
      " [ 3.78369498e+00]\n",
      " [ 3.16614890e+00]\n",
      " [ 1.90005195e+00]\n",
      " [ 8.24454403e+00]\n",
      " [ 9.08861542e+00]\n",
      " [ 5.13512707e+00]\n",
      " [ 2.00373769e+00]\n",
      " [ 2.35677838e+00]\n",
      " [ 7.16838026e+00]\n",
      " [ 2.55657220e+00]\n",
      " [ 3.11958361e+00]\n",
      " [ 8.94762707e+00]\n",
      " [ 1.92238843e+00]\n",
      " [ 1.19630957e+00]\n",
      " [ 2.64928126e+00]\n",
      " [ 3.62311053e+00]\n",
      " [ 3.54150534e+00]\n",
      " [ 8.71421814e-01]\n",
      " [ 7.63996649e+00]\n",
      " [ 5.81734896e-01]\n",
      " [ 4.79597807e+00]\n",
      " [ 1.12528831e-01]\n",
      " [ 1.68626904e+00]\n",
      " [ 4.79597807e+00]\n",
      " [ 1.32744479e+00]\n",
      " [ 1.21097362e+00]\n",
      " [ 6.59135103e+00]\n",
      " [ 3.88053536e+00]\n",
      " [ 2.70004630e+00]\n",
      " [ 2.57863188e+00]\n",
      " [ 2.52092123e+00]\n",
      " [ 1.42381060e+00]\n",
      " [ 4.79597807e+00]\n",
      " [ 2.25441575e+00]\n",
      " [ 1.64018047e+00]\n",
      " [ 3.99259162e+00]\n",
      " [ 9.38544178e+00]\n",
      " [ 7.18632102e-01]\n",
      " [ 8.91027355e+00]\n",
      " [ 1.66121531e+00]\n",
      " [ 2.02816820e+00]\n",
      " [ 8.00562572e+00]\n",
      " [ 1.27828085e+00]\n",
      " [ 5.94980431e+00]\n",
      " [ 1.95008844e-01]\n",
      " [ 2.16855145e+00]\n",
      " [ 2.22916865e+00]\n",
      " [ 4.67449379e+00]\n",
      " [ 2.35677838e+00]\n",
      " [ 1.10201383e+00]\n",
      " [ 2.98721337e+00]\n",
      " [ 5.69706631e+00]\n",
      " [ 4.09896374e+00]\n",
      " [ 8.25491071e-01]\n",
      " [ 7.99323440e-01]\n",
      " [ 6.35868311e+00]\n",
      " [ 3.53562951e+00]\n",
      " [ 8.86156678e-01]\n",
      " [ 3.15949821e+00]\n",
      " [ 5.77902496e-02]\n",
      " [ 6.35616660e-01]\n",
      " [ 1.43028009e+00]\n",
      " [ 4.62860882e-01]\n",
      " [ 3.51675105e+00]\n",
      " [ 1.72897863e+00]\n",
      " [ 3.55700344e-01]\n",
      " [ 9.20057869e+00]\n",
      " [ 8.03460789e+00]\n",
      " [ 1.65571082e+00]\n",
      " [ 2.31647325e+00]\n",
      " [ 3.75149846e+00]\n",
      " [ 3.06881857e+00]\n",
      " [ 5.66942167e+00]\n",
      " [ 5.53488970e+00]\n",
      " [ 7.73821592e+00]\n",
      " [ 6.06584549e-01]\n",
      " [ 8.24523067e+00]\n",
      " [ 3.13324642e+00]\n",
      " [ 9.83480573e-01]\n",
      " [ 7.09433079e+00]\n",
      " [ 5.04229879e+00]\n",
      " [ 8.08920860e-01]\n",
      " [ 3.19692254e+00]\n",
      " [ 1.72666788e-01]\n",
      " [ 2.61101127e+00]\n",
      " [ 3.27351141e+00]\n",
      " [ 4.09024477e+00]\n",
      " [ 2.11207062e-01]\n",
      " [ 6.34379983e-01]\n",
      " [ 6.04153204e+00]\n",
      " [ 6.36471987e+00]\n",
      " [ 1.85385048e+00]\n",
      " [ 3.35473084e+00]\n",
      " [ 5.04120111e+00]\n",
      " [ 1.18087626e+00]\n",
      " [ 9.79420066e-01]\n",
      " [-1.13274246e-01]\n",
      " [ 6.13089180e+00]\n",
      " [ 4.79488039e+00]\n",
      " [-1.00379884e-01]\n",
      " [ 8.64024067e+00]\n",
      " [ 4.85888869e-01]\n",
      " [ 6.42485285e+00]\n",
      " [ 4.22773886e+00]\n",
      " [ 3.27351141e+00]\n",
      " [ 3.12028146e+00]\n",
      " [ 1.98072994e+00]\n",
      " [ 8.44524479e+00]\n",
      " [ 6.93005800e+00]\n",
      " [ 5.40480471e+00]\n",
      " [ 9.99647141e-01]\n",
      " [ 1.77353156e+00]\n",
      " [ 1.40630710e+00]\n",
      " [ 4.11400604e+00]\n",
      " [ 1.36013567e+00]\n",
      " [ 2.30471230e+00]\n",
      " [ 5.29253197e+00]\n",
      " [ 2.97436380e+00]\n",
      " [ 1.96219039e+00]\n",
      " [ 7.63708735e+00]\n",
      " [ 2.79944468e+00]\n",
      " [ 1.08672154e+00]\n",
      " [ 1.63709342e+00]\n",
      " [ 4.21062851e+00]\n",
      " [ 9.19975400e-01]\n",
      " [ 4.86972952e+00]\n",
      " [ 2.31450033e+00]\n",
      " [ 7.17287636e+00]\n",
      " [ 4.87474060e+00]\n",
      " [ 8.20931530e+00]\n",
      " [ 9.26032305e-01]\n",
      " [ 2.14971447e+00]\n",
      " [ 9.87275243e-02]\n",
      " [ 8.64081860e-01]\n",
      " [ 5.79526186e-01]\n",
      " [ 6.07980394e+00]\n",
      " [ 2.60354280e+00]\n",
      " [ 2.20512462e+00]\n",
      " [ 4.99573231e+00]\n",
      " [ 2.08031750e+00]\n",
      " [ 6.55938435e+00]\n",
      " [ 3.20357370e+00]\n",
      " [ 1.18959105e+00]\n",
      " [ 4.22773886e+00]\n",
      " [ 2.11207062e-01]\n",
      " [ 5.83949375e+00]\n",
      " [ 8.84228039e+00]\n",
      " [ 7.85012007e-01]\n",
      " [ 2.16782117e+00]\n",
      " [ 5.71782351e+00]\n",
      " [ 5.09884453e+00]\n",
      " [ 9.05136204e+00]\n",
      " [ 7.19406128e-01]\n",
      " [ 4.18295383e+00]\n",
      " [ 7.99866438e-01]\n",
      " [ 2.77358651e+00]\n",
      " [ 6.69440126e+00]\n",
      " [ 3.75465542e-01]\n",
      " [ 1.74758935e+00]\n",
      " [ 8.81543350e+00]\n",
      " [ 8.35883021e-01]\n",
      " [ 2.85707951e+00]\n",
      " [ 8.23763132e-01]\n",
      " [ 7.31523752e-01]\n",
      " [ 2.56518245e+00]\n",
      " [ 6.28983641e+00]\n",
      " [ 2.70592237e+00]\n",
      " [ 4.07658148e+00]\n",
      " [ 8.64930820e+00]\n",
      " [ 5.43523073e+00]\n",
      " [ 6.39503002e-01]\n",
      " [-1.04131520e-01]\n",
      " [ 6.52597952e+00]\n",
      " [ 4.03915644e+00]\n",
      " [ 6.01702452e-01]\n",
      " [ 6.90930033e+00]\n",
      " [ 7.45099068e-01]\n",
      " [ 1.92607999e+00]\n",
      " [ 3.16113877e+00]\n",
      " [ 1.63039279e+00]\n",
      " [ 8.97000194e-01]\n",
      " [ 4.93758440e+00]\n",
      " [ 3.54150534e+00]\n",
      " [ 5.20875931e+00]\n",
      " [-7.22530484e-03]\n",
      " [ 2.46098018e+00]\n",
      " [ 4.56567144e+00]\n",
      " [ 1.64699423e+00]\n",
      " [ 2.59204817e+00]\n",
      " [ 2.24405479e+00]\n",
      " [ 4.79488039e+00]\n",
      " [ 8.60971737e+00]\n",
      " [ 2.49934077e+00]\n",
      " [ 3.13737702e+00]\n",
      " [ 4.87604761e+00]\n",
      " [ 5.89812458e-01]\n",
      " [ 4.79488039e+00]\n",
      " [ 9.05136204e+00]\n",
      " [ 3.95516658e+00]\n",
      " [ 7.63708735e+00]\n",
      " [ 1.12961912e+00]\n",
      " [ 3.20944953e+00]\n",
      " [ 6.44561148e+00]\n",
      " [ 5.29127121e-02]\n",
      " [ 5.49695110e+00]\n",
      " [ 3.09885412e-01]\n",
      " [ 1.08575666e+00]\n",
      " [ 8.96395016e+00]\n",
      " [ 2.31647325e+00]\n",
      " [ 1.41474962e+00]\n",
      " [ 6.87878251e-01]\n",
      " [ 5.63745403e+00]\n",
      " [ 1.04791939e-01]\n",
      " [ 2.81735361e-02]\n",
      " [ 1.97211874e+00]\n",
      " [ 7.83912802e+00]\n",
      " [ 4.79488039e+00]\n",
      " [ 6.03736877e+00]\n",
      " [ 5.38096607e-01]\n",
      " [ 4.93758440e+00]\n",
      " [ 1.42381060e+00]\n",
      " [ 3.03797793e+00]\n",
      " [ 7.83940911e-01]\n",
      " [ 6.16268015e+00]\n",
      " [ 4.93758440e+00]\n",
      " [ 2.91481829e+00]\n",
      " [ 2.65928459e+00]\n",
      " [-3.76095474e-02]\n",
      " [ 3.83026052e+00]\n",
      " [ 4.11045456e+00]\n",
      " [ 8.54821205e-01]\n",
      " [ 2.58701062e+00]\n",
      " [ 5.95326662e+00]\n",
      " [ 1.30568314e+00]\n",
      " [ 6.75844812e+00]\n",
      " [ 3.06009912e+00]\n",
      " [ 3.91522074e+00]\n",
      " [ 8.56452942e-01]\n",
      " [ 1.66017926e+00]\n",
      " [ 2.64809728e-02]\n",
      " [ 4.15838182e-01]\n",
      " [ 1.04791939e-01]\n",
      " [ 3.02354884e+00]\n",
      " [ 1.30568314e+00]\n",
      " [ 6.63411975e-01]\n",
      " [ 2.85707951e+00]\n",
      " [ 5.81873512e+00]\n",
      " [ 4.59964752e+00]\n",
      " [ 7.85988522e+00]\n",
      " [ 2.70084286e+00]\n",
      " [ 7.25798368e-01]\n",
      " [ 1.97945583e+00]\n",
      " [ 5.16038084e+00]\n",
      " [ 6.28983641e+00]\n",
      " [ 8.20436239e-01]\n",
      " [ 8.04116631e+00]\n",
      " [ 3.67163968e+00]\n",
      " [ 2.31612802e+00]\n",
      " [ 7.21620274e+00]\n",
      " [ 3.75040102e+00]\n",
      " [ 8.21684551e+00]\n",
      " [ 3.15327615e-01]\n",
      " [ 6.62689352e+00]\n",
      " [ 2.70084286e+00]\n",
      " [ 4.39920998e+00]\n",
      " [ 3.95929694e+00]\n",
      " [ 2.91481829e+00]\n",
      " [ 7.11133957e+00]\n",
      " [ 1.08672154e+00]\n",
      " [ 9.09299564e+00]\n",
      " [ 1.54181600e+00]\n",
      " [ 4.47712034e-01]\n",
      " [ 2.97776729e-01]\n",
      " [ 3.49494004e+00]\n",
      " [ 2.70084286e+00]\n",
      " [ 1.14901476e+01]\n",
      " [ 3.24099827e+00]\n",
      " [ 6.08876848e+00]\n",
      " [ 4.91138935e+00]\n",
      " [ 3.87468147e+00]\n",
      " [ 6.01577425e+00]\n",
      " [ 4.04503202e+00]\n",
      " [ 7.79286289e+00]\n",
      " [ 7.72584057e+00]\n",
      " [ 9.86737919e+00]\n",
      " [ 3.06597543e+00]\n",
      " [ 7.90712118e+00]\n",
      " [-1.04131520e-01]\n",
      " [ 2.64405370e+00]\n",
      " [ 3.87574226e-01]\n",
      " [ 3.90510964e+00]\n",
      " [ 2.82908249e+00]\n",
      " [ 3.55861497e+00]\n",
      " [ 1.97969353e+00]\n",
      " [ 1.18284929e+00]\n",
      " [ 7.41520643e-01]\n",
      " [ 1.52308917e+00]\n",
      " [ 8.66804028e+00]\n",
      " [ 3.95765638e+00]\n",
      " [ 1.00565577e+01]\n",
      " [ 7.63708735e+00]\n",
      " [ 2.49506974e+00]\n",
      " [ 2.70592237e+00]\n",
      " [ 3.98141837e+00]\n",
      " [ 1.08025205e+00]\n",
      " [ 1.42717373e+00]\n",
      " [ 8.54821205e-01]\n",
      " [ 7.79888988e-01]\n",
      " [ 2.64809728e-02]\n",
      " [ 4.20148706e+00]\n",
      " [ 4.79488039e+00]\n",
      " [ 2.77308941e+00]\n",
      " [ 1.41371346e+00]\n",
      " [ 3.43200827e+00]\n",
      " [ 4.15838182e-01]\n",
      " [ 4.05281973e+00]\n",
      " [ 5.20854187e+00]\n",
      " [ 7.59082365e+00]\n",
      " [ 8.17020988e+00]\n",
      " [ 5.41465664e+00]\n",
      " [ 8.06556463e-01]\n",
      " [ 3.03210211e+00]\n",
      " [ 3.57892966e+00]\n",
      " [ 1.88114178e+00]\n",
      " [-1.44563615e-02]\n",
      " [ 8.56893921e+00]\n",
      " [ 5.13919055e-01]\n",
      " [-3.76095474e-02]\n",
      " [ 5.22633505e+00]\n",
      " [ 5.06725168e+00]\n",
      " [ 2.91481829e+00]\n",
      " [ 1.50108743e+00]\n",
      " [ 8.96753025e+00]\n",
      " [ 5.91971159e-01]\n",
      " [ 9.72749901e+00]\n",
      " [ 7.99866438e-01]\n",
      " [ 6.70967245e+00]\n",
      " [ 5.32683253e-01]\n",
      " [ 5.57789624e-01]\n",
      " [ 6.69594097e+00]\n",
      " [ 8.00776291e+00]\n",
      " [ 3.34627271e+00]\n",
      " [ 9.65999126e+00]\n",
      " [ 4.27946866e-01]\n",
      " [ 7.70038664e-02]\n",
      " [ 4.56567144e+00]\n",
      " [ 4.99964571e+00]\n",
      " [ 7.92630911e-01]\n",
      " [ 1.79177856e+00]\n",
      " [ 6.62689352e+00]\n",
      " [ 2.31025195e+00]\n",
      " [ 1.52205312e+00]\n",
      " [ 3.63677382e+00]\n",
      " [ 1.88114178e+00]\n",
      " [ 9.26915932e+00]\n",
      " [ 9.37758160e+00]\n",
      " [ 3.22681522e+00]\n",
      " [ 7.22752237e+00]\n",
      " [ 6.72588205e+00]\n",
      " [ 2.30574870e+00]\n",
      " [ 6.03846598e+00]\n",
      " [ 8.15706730e-01]\n",
      " [ 2.77095580e+00]\n",
      " [ 6.10114431e+00]\n",
      " [ 9.82026458e-01]\n",
      " [ 7.54840255e-01]\n",
      " [ 4.88233268e-02]\n",
      " [ 3.34039664e+00]\n",
      " [ 7.69660711e-01]\n",
      " [ 1.52883172e+00]\n",
      " [ 6.35137367e+00]\n",
      " [ 2.71205395e-01]\n",
      " [-1.42545909e-01]\n",
      " [ 2.06673121e+00]\n",
      " [ 1.62945580e+00]\n",
      " [ 7.99866438e-01]\n",
      " [ 9.05462503e-01]\n",
      " [ 2.19613481e+00]\n",
      " [ 6.02287591e-01]\n",
      " [ 1.36834145e+00]\n",
      " [ 1.28589749e+00]\n",
      " [ 4.36620188e+00]\n",
      " [ 1.11669874e+00]\n",
      " [ 1.54590428e+00]\n",
      " [ 3.23195291e+00]\n",
      " [ 2.45351148e+00]\n",
      " [ 2.96274471e+00]\n",
      " [ 8.31394434e-01]\n",
      " [ 8.84892583e-01]\n",
      " [ 4.03414679e+00]\n",
      " [ 5.61669636e+00]\n",
      " [ 2.70851135e+00]\n",
      " [ 2.77599311e+00]\n",
      " [ 8.97000194e-01]\n",
      " [ 2.02149630e+00]\n",
      " [ 1.99514484e+00]\n",
      " [ 3.06597543e+00]\n",
      " [ 6.09865952e+00]\n",
      " [ 4.18185568e+00]\n",
      " [ 6.98846221e-01]\n",
      " [ 2.20616078e+00]\n",
      " [ 1.97748268e+00]\n",
      " [ 1.29464900e+00]\n",
      " [ 2.01696801e+00]\n",
      " [ 5.58993912e+00]\n",
      " [ 6.68535113e-01]\n",
      " [ 4.98701334e+00]\n",
      " [ 6.19776368e-01]\n",
      " [ 2.19613481e+00]\n",
      " [-9.34733152e-02]\n",
      " [ 6.24038839e+00]\n",
      " [ 7.46818209e+00]\n",
      " [ 2.76107907e+00]\n",
      " [ 4.89279330e-01]\n",
      " [ 7.56312227e+00]\n",
      " [ 3.73118496e+00]\n",
      " [ 5.78109980e-01]\n",
      " [ 1.52007997e+00]\n",
      " [ 2.66191554e+00]\n",
      " [ 4.28547668e+00]\n",
      " [ 1.74454594e+00]\n",
      " [ 5.21719360e+00]\n",
      " [ 1.29464900e+00]\n",
      " [ 6.49234354e-01]\n",
      " [ 7.03959227e-01]\n",
      " [ 7.06850719e+00]\n",
      " [ 4.70000362e+00]\n",
      " [ 5.89812458e-01]\n",
      " [ 5.60100889e+00]\n",
      " [ 1.75101554e+00]\n",
      " [ 8.44524479e+00]\n",
      " [ 3.12775111e+00]\n",
      " [ 5.79526186e-01]\n",
      " [ 1.17108822e+00]\n",
      " [ 1.18886209e+00]\n",
      " [ 2.91187787e+00]\n",
      " [ 8.84892583e-01]\n",
      " [ 2.19637275e+00]\n",
      " [ 3.95015669e+00]\n",
      " [ 2.07928157e+00]\n",
      " [ 1.63820755e+00]\n",
      " [ 4.06744051e+00]\n",
      " [ 7.84115267e+00]\n",
      " [ 2.53993154e+00]\n",
      " [ 2.68560815e+00]\n",
      " [ 1.40630710e+00]\n",
      " [ 4.95834160e+00]\n",
      " [ 1.97969353e+00]\n",
      " [ 8.91877174e-01]\n",
      " [ 8.79143119e-01]\n",
      " [ 3.02781940e+00]\n",
      " [ 1.30994129e+00]\n",
      " [ 1.60418242e-01]\n",
      " [ 6.97386932e+00]\n",
      " [ 1.63717127e+00]\n",
      " [ 1.52339864e+00]\n",
      " [ 2.31647325e+00]\n",
      " [ 7.25172162e-01]\n",
      " [ 6.05677962e-01]\n",
      " [ 6.62689352e+00]\n",
      " [ 4.49110842e+00]\n",
      " [ 2.43906927e+00]\n",
      " [ 6.54199457e+00]]\n"
     ]
    }
   ],
   "source": [
    "#example on how to use our newly trained model on how to make predictions on unseen data\n",
    "#we will pretend our new data is saved in a dataframecalled 'test_X')\n",
    "\n",
    "test_df = pd.read_csv('Datasets/hourly_wages_data.csv')\n",
    "test_X = test_df.drop(columns=['wage_per_hour'])\n",
    "\n",
    "test_y_predictions = model.predict(test_X)\n",
    "\n",
    "print (test_y_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you increase the number of nodes and layers in a model, the model capacity increases. Increasing model capacity can lead to a more accurate model, up to a certain point, at which the model will stop improving. Generally, the more training data you provide, the larger the model should be. We are only using a tiny amount of data, so our model is pretty small. The larger the model, the more computational capacity it requires and it will take longer to train.\n",
    "\n",
    "Let's create a new model using the same training data as our previous model. This time, we will add a layer and increase the nodes in each layer to 200. We will train the model to see if increasing the model capacity will improve our validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a new model on the same data to show the effect of increasing model capacity\n",
    "\n",
    "#create model\n",
    "model_mc = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model_mc.add(Dense(200, activation='relu', input_shape=(n_cols,)))\n",
    "model_mc.add(Dense(200, activation='relu'))\n",
    "model_mc.add(Dense(200, activation='relu'))\n",
    "model_mc.add(Dense(1))\n",
    "\n",
    "#compile model using mse as a measure of model performance\n",
    "model_mc.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 427 samples, validate on 107 samples\n",
      "Epoch 1/30\n",
      "427/427 [==============================] - 0s 1ms/step - loss: 5.8293 - val_loss: 1.5123\n",
      "Epoch 2/30\n",
      "427/427 [==============================] - 0s 91us/step - loss: 1.0216 - val_loss: 0.8081\n",
      "Epoch 3/30\n",
      "427/427 [==============================] - 0s 108us/step - loss: 0.3349 - val_loss: 0.6554\n",
      "Epoch 4/30\n",
      "427/427 [==============================] - 0s 91us/step - loss: 0.2064 - val_loss: 0.6740\n",
      "Epoch 5/30\n",
      "427/427 [==============================] - 0s 101us/step - loss: 0.1538 - val_loss: 0.7826\n",
      "Epoch 6/30\n",
      "427/427 [==============================] - 0s 101us/step - loss: 0.1436 - val_loss: 0.8272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4b6440940>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model_mc.fit(train_X, train_y, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that by increasing our model capacity, we have improved our validation loss from 29.65 in our old model to 28.39 in our new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's move on to building our model for classification. Since many steps will be a repeat from the previous model, I will only go over new concepts.\n",
    "\n",
    "For this next model, we are going to predict if patients have diabetes or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in training data\n",
    "train_df_2 = pd.read_csv('Datasets/diabetes_data.csv')\n",
    "\n",
    "#view data structure\n",
    "train_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with all training data except the target column\n",
    "train_X_2 = train_df_2.drop(columns=['diabetes'])\n",
    "\n",
    "#check that the target variable has been removed\n",
    "train_X_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When separating the target column, we need to call the 'to_categorical()' function so that column will be 'one-hot encoded'. Currently, a patient with no diabetes is represented with a 0 in the diabetes column and a patient with diabetes is represented with a 1. \n",
    "\n",
    "With one-hot encoding, the integer will be removed and a binary variable is inputted for each category. In our case, we have two categories: no diabetes and diabetes.\n",
    "\n",
    "A patient with no diabetes will be represented by [1 0] and a patient with diabetes will be represented by [0 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target column\n",
    "train_y_2 = to_categorical(train_df_2.diabetes)\n",
    "\n",
    "#vcheck that target column has been converted\n",
    "train_y_2[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last layer of our model has 2 nodes - one for each option: the patient has diabetes or they don't.\n",
    "\n",
    "The activation is 'softmax'. Softmax makes the output sum up to 1 so the output can be interpreted as probabilities. The model will then make its prediction based on which option has a higher probability.\n",
    "\n",
    "We will use 'categorical_crossentropy' for our loss function. This is the most common choice for classification. A lower score indicates that the model is performing better.\n",
    "\n",
    "To make things even easier to interpret, we will use the 'accuracy' metric to see the accuracy score on the validation set at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(processor):\n",
    "    #create model\n",
    "    model_2 = Sequential()\n",
    "\n",
    "    #get number of columns in training data\n",
    "    n_cols_2 = train_X_2.shape[1]\n",
    "\n",
    "    #add layers to model\n",
    "    model_2.add(Dense(250, activation='relu', input_shape=(n_cols_2,)))\n",
    "    model_2.add(Dense(250, activation='relu'))\n",
    "    model_2.add(Dense(250, activation='relu'))\n",
    "    model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "model_2.fit(train_X_2, train_y_2, epochs=30, validation_split=0.2, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
